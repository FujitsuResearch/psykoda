
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>psykoda.detection &#8212; psykoda  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for psykoda.detection</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Anomaly Detection and Explanation.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">logging</span> <span class="kn">import</span> <span class="n">getLogger</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">shap</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span><span class="p">,</span> <span class="n">Series</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Layer</span><span class="p">,</span> <span class="n">LeakyReLU</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">Sequence</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">KERNEL_INITIALIZER</span> <span class="o">=</span> <span class="s2">&quot;he_normal&quot;</span>
<span class="n">LAYERNAME_ENCODER_OUTPUT</span> <span class="o">=</span> <span class="s2">&quot;encoder_output&quot;</span>
<span class="n">REGULARIZER_L2</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">L2</span> <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span> <span class="o">==</span> <span class="s2">&quot;2.3.0&quot;</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span>
<span class="p">)</span>


<div class="viewcode-block" id="generator_autoencoder_training"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.generator_autoencoder_training">[docs]</a><span class="k">class</span> <span class="nc">generator_autoencoder_training</span><span class="p">(</span><span class="n">Sequence</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sparse matrix as batches of dense arrays&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps_per_epoch</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="n">batch_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
        <span class="c1"># autoencoder</span>
        <span class="k">return</span> <span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_X</span>

<div class="viewcode-block" id="generator_autoencoder_training.on_epoch_end"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.generator_autoencoder_training.on_epoch_end">[docs]</a>    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># add ops of shuffling all samples, if available</span>
        <span class="k">pass</span></div></div>


<div class="viewcode-block" id="loss_sad"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.loss_sad">[docs]</a><span class="k">def</span> <span class="nf">loss_sad</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Loss function for Deep SAD</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] L. Ruff, R. A. Vandermeulen, N. Görnitz, A. Binder, E. Müller, K.-R. Müller, M. Kloft,</span>
<span class="sd">    &quot;Deep Semi-Supervised Anomaly Detection&quot;, https://arxiv.org/abs/1906.02694</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">labels</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Loss function for Deep SAD</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        labels</span>
<span class="sd">            ground truth labels</span>

<span class="sd">            :shape: (batch_size, 1)</span>

<span class="sd">        embeddings</span>
<span class="sd">            outputs of encoder phi</span>

<span class="sd">            :shape: (batch_size, dim_embedding)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># flatten GT</span>

        <span class="n">loss_nolabeled</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
            <span class="p">(</span><span class="n">embeddings</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># loss for not labeled samples</span>
        <span class="n">loss_labeled</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">loss_nolabeled</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># loss for labeled samples</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>

        <span class="n">loss_total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">loss_nolabeled</span><span class="p">,</span> <span class="n">loss_labeled</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_total</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">return</span> <span class="n">loss_function</span></div>


<div class="viewcode-block" id="dense_block"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.dense_block">[docs]</a><span class="k">def</span> <span class="nf">dense_block</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">lam</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Layer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Basic block (Dense-LeakyReLU layers) of multi layer perceptron.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    input</span>
<span class="sd">        input of block</span>
<span class="sd">    units</span>
<span class="sd">        number of the units in the Dense layer</span>
<span class="sd">    lam</span>
<span class="sd">        regularization parameter on the weights in Dense layer</span>
<span class="sd">    name</span>
<span class="sd">        name of block; &quot;_dense&quot; and &quot;_LeakyReLU&quot; are appended for the layers</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    output</span>
<span class="sd">        Dense-LeakyReLu layers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span>
        <span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_dense&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">REGULARIZER_L2</span><span class="p">(</span><span class="n">lam</span><span class="p">),</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">KERNEL_INITIALIZER</span><span class="p">,</span>
    <span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">LeakyReLU</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_LeakyReLU&quot;</span><span class="p">)(</span><span class="n">output</span><span class="p">)</span></div>


<div class="viewcode-block" id="DeepSAD"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.DeepSAD">[docs]</a><span class="k">class</span> <span class="nc">DeepSAD</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Deep SAD Semi-supervised Anomaly Detector.</span>

<span class="sd">    Translated from `paper author Lukas Ruff&#39;s PyTorch implementation &lt;https://github.com/lukasruff/Deep-SAD-PyTorch&gt;`_</span>
<span class="sd">    into TensorFlow.</span>

<span class="sd">    .. todo:: more detailed description, including comparison with PyTorch version.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    dim_hidden</span>
<span class="sd">        from Config</span>
<span class="sd">    eta</span>
<span class="sd">        from Config</span>
<span class="sd">    lam</span>
<span class="sd">        from Config</span>
<span class="sd">    path_pretrained_model</span>
<span class="sd">        from Config</span>
<span class="sd">    dim_input</span>
<span class="sd">        number of features</span>
<span class="sd">    history</span>
<span class="sd">    detector</span>

<span class="sd">    Original License</span>
<span class="sd">    ----------------</span>
<span class="sd">    MIT License</span>

<span class="sd">    Copyright (c) 2019 lukasruff</span>

<span class="sd">    Permission is hereby granted, free of charge, to any person obtaining a copy</span>
<span class="sd">    of this software and associated documentation files (the &quot;Software&quot;), to deal</span>
<span class="sd">    in the Software without restriction, including without limitation the rights</span>
<span class="sd">    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span>
<span class="sd">    copies of the Software, and to permit persons to whom the Software is</span>
<span class="sd">    furnished to do so, subject to the following conditions:</span>

<span class="sd">    The above copyright notice and this permission notice shall be included in all</span>
<span class="sd">    copies or substantial portions of the Software.</span>

<span class="sd">    THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="sd">    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="sd">    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span>
<span class="sd">    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="sd">    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span>
<span class="sd">    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span>
<span class="sd">    SOFTWARE.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DeepSAD.Config"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.DeepSAD.Config">[docs]</a>    <span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span>
    <span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Configuration for DeepSAD model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dim_hidden</span>
<span class="sd">            number of units in hidden layers</span>
<span class="sd">        eta</span>
<span class="sd">            Deep SAD regularization hyperparameter eta (must be 0 &lt; eta)</span>
<span class="sd">            balancing the loss for labeled and unlabeled samples</span>
<span class="sd">        lam</span>
<span class="sd">            regularization parameter on L2-norm of weights</span>
<span class="sd">        path_pretrained_model</span>
<span class="sd">            path to pretrained model (currently unused)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">dim_hidden</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">field</span><span class="p">(</span>
            <span class="n">default_factory</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">eta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">lam</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span>
        <span class="n">path_pretrained_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></div>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_hidden</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">dim_hidden</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">lam</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">path_pretrained_model</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">path_pretrained_model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dim_input</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">detector</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_build_encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Build encoder model (Multi Layer Perceptron)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        encoder</span>
<span class="sd">            input: (dim_input, ), output: (dim_hidden[-1], )</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_input</span><span class="p">,),</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;encoder_input&quot;</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_hidden</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">dense_block</span><span class="p">(</span>
                <span class="n">outputs</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lam</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;encoder_block&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span>
            <span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_hidden</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">LAYERNAME_ENCODER_OUTPUT</span><span class="p">,</span>
            <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">REGULARIZER_L2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lam</span><span class="p">),</span>
            <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">KERNEL_INITIALIZER</span><span class="p">,</span>
        <span class="p">)(</span><span class="n">outputs</span><span class="p">)</span>

        <span class="n">encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">encoder</span>

    <span class="k">def</span> <span class="nf">_build_autoencoder</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">encoder_input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Build autoencoder model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        encoder_input</span>
<span class="sd">            input of the first layer of the encoder</span>
<span class="sd">        encoder_ouput</span>
<span class="sd">            output of the last layer of the encoder (bottleneck layer)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        autoencoder</span>
<span class="sd">            input: (dim_input, ), output: (self.dim_input, )</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">LeakyReLU</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;decoder_1st_LeakyReLU&quot;</span><span class="p">)(</span><span class="n">encoder_output</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_hidden</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">dense_block</span><span class="p">(</span>
                <span class="n">outputs</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lam</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;decoder_block&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span>
            <span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_input</span><span class="p">,</span>
            <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;decoder_output&quot;</span><span class="p">,</span>
            <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">REGULARIZER_L2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lam</span><span class="p">),</span>
            <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">KERNEL_INITIALIZER</span><span class="p">,</span>
        <span class="p">)(</span><span class="n">outputs</span><span class="p">)</span>

        <span class="n">autoencoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">encoder_input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">autoencoder</span>

    <span class="k">def</span> <span class="nf">_build_detector</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">center</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build anomaly detector model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        encoder</span>
<span class="sd">        center</span>
<span class="sd">            center of embeddings (encoded feature) (&quot;c&quot; in the paper)</span>

<span class="sd">            :shape: (dim_embedding, )</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        detector</span>
<span class="sd">            anomaly detector</span>
<span class="sd">            detector(x) = \| encoder(x) - c \|^2</span>
<span class="sd">            the higher, the more anomalous</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">center</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span>

        <span class="n">score</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">((</span><span class="n">encoder</span><span class="o">.</span><span class="n">output</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">center</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">detector</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">encoder</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">score</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">detector</span>

<div class="viewcode-block" id="DeepSAD.TrainConfig"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.DeepSAD.TrainConfig">[docs]</a>    <span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span>
    <span class="k">class</span> <span class="nc">TrainConfig</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Configuration of training process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        epochs_pretrain</span>
<span class="sd">            epochs for pretraining (center initialization)</span>
<span class="sd">        epochs_train</span>
<span class="sd">            epochs for training of detector</span>
<span class="sd">        learning_rate</span>
<span class="sd">            learning rate of optimizer</span>
<span class="sd">        batch_size</span>
<span class="sd">            batch size</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">epochs_pretrain</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">epochs_train</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span></div>

<div class="viewcode-block" id="DeepSAD.train"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.DeepSAD.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">],</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">path_model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">TrainConfig</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Train anomaly detector (self.detector) with encoder (local variable).</span>

<span class="sd">        Set self.detector, self.dim_input and self.history.</span>
<span class="sd">        Save encoder to path_model and loss-epoch plot next to it.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X</span>
<span class="sd">            feature matrix</span>

<span class="sd">            :shape: (n_samples, n_features)</span>
<span class="sd">        y</span>
<span class="sd">            label</span>
<span class="sd">                0</span>
<span class="sd">                    not labeled as normal</span>
<span class="sd">                1</span>
<span class="sd">                    labeled as normal</span>

<span class="sd">            :shape: (n_samples, )</span>
<span class="sd">        path_model</span>
<span class="sd">            path &#39;\*\*.h5&#39; to save trained model</span>
<span class="sd">        verbose</span>
<span class="sd">            verbosity of logging/output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="k">assert</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">path_model</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dim_input</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>

        <span class="c1"># training autoencoder for the weight and center initialization</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">path_pretrained_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;start detector weight initialization with epochs </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">config</span><span class="o">.</span><span class="n">epochs_pretrain</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_encoder</span><span class="p">()</span>
            <span class="n">autoencoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_autoencoder</span><span class="p">(</span>
                <span class="n">encoder</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">encoder</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>
            <span class="p">)</span>
            <span class="n">autoencoder</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">):</span>
                <span class="n">generator</span> <span class="o">=</span> <span class="n">generator_autoencoder_training</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="n">autoencoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                    <span class="n">generator</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epochs_pretrain</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">autoencoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epochs_pretrain</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;load pre-trained detector from </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">path_pretrained_model</span><span class="p">)</span>
            <span class="n">detector</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">path_pretrained_model</span><span class="p">)</span>
            <span class="n">encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">detector</span><span class="o">.</span><span class="n">input</span><span class="p">,</span>
                <span class="n">outputs</span><span class="o">=</span><span class="n">detector</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="n">LAYERNAME_ENCODER_OUTPUT</span><span class="p">)</span><span class="o">.</span><span class="n">output</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">center</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_sad</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="n">center</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">)</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">ModelCheckpoint</span><span class="p">(</span>
                <span class="n">filepath</span><span class="o">=</span><span class="n">path_model</span><span class="p">,</span>
                <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">]</span>

        <span class="c1"># encoder training</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;start detector training with epochs </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">epochs_train</span><span class="p">)</span>
        <span class="n">encoder</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epochs_train</span><span class="p">,</span>
            <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">encoder</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">path_model</span><span class="p">)</span>

        <span class="c1"># build anomaly detector from the trained encoder and center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">detector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_detector</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">center</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">detector</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path_model</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;save detector on </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">path_model</span><span class="p">)</span>

        <span class="c1"># plot and save training process for debugging</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;training loss&quot;</span><span class="p">)</span>
        <span class="c1"># plt.plot(epochs, val_loss, &#39;b&#39; , label= &#39;validation loss&#39;)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;detector training process&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">path_model</span><span class="p">),</span> <span class="s2">&quot;training_process.png&quot;</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

<div class="viewcode-block" id="DeepSAD.load_detector"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.DeepSAD.load_detector">[docs]</a>    <span class="k">def</span> <span class="nf">load_detector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path_model</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load pre-trained anomaly detector&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">detector</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">path_model</span><span class="p">)</span></div>

<div class="viewcode-block" id="DeepSAD.compute_anomaly_score"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.DeepSAD.compute_anomaly_score">[docs]</a>    <span class="k">def</span> <span class="nf">compute_anomaly_score</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute anomaly score</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X</span>
<span class="sd">            :shape: (n_samples, n_features)</span>
<span class="sd">        scale</span>
<span class="sd">            scale anomaly scores</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : ndarray</span>
<span class="sd">            anomaly scores</span>

<span class="sd">            :shape: (n_samples, )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Without type annotation &quot;: ndarray&quot; after score, sphinx treats &quot;score&quot; as type.</span>
        <span class="c1"># some text and a blank line is needed before :shape: too.</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detector</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">scale</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">score</span>

        <span class="c1"># scale anomaly score</span>
        <span class="n">med</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">score</span> <span class="o">-</span> <span class="n">med</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">var</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">med</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">score</span> <span class="o">-</span> <span class="n">med</span><span class="p">)</span> <span class="o">/</span> <span class="n">var</span></div>

<div class="viewcode-block" id="DeepSAD.compute_embeddings"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.DeepSAD.compute_embeddings">[docs]</a>    <span class="k">def</span> <span class="nf">compute_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Compute input embeddings (latent representation/output of bottleneck layer)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X</span>
<span class="sd">            :shape: (n_samples, n_features)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        feature : ndarray</span>
<span class="sd">            embedding for each input</span>

<span class="sd">            :shape: (n_samples, dim_embedding)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="n">encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">detector</span><span class="o">.</span><span class="n">input</span><span class="p">,</span>
            <span class="n">outputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">detector</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="n">LAYERNAME_ENCODER_OUTPUT</span><span class="p">)</span><span class="o">.</span><span class="n">output</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">encoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>

<div class="viewcode-block" id="DeepSAD.explain_anomaly"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.DeepSAD.explain_anomaly">[docs]</a>    <span class="k">def</span> <span class="nf">explain_anomaly</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X_anomaly</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">],</span>
        <span class="n">background_samples</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">],</span>
        <span class="n">zero_correction</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">shapvalue_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute Shapley values (degree of contribution to anomaly) of each feature for anomaly samples</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_anomaly</span>
<span class="sd">            feature matrix of anomaly samples</span>

<span class="sd">            :shape: (n_anomaly_samples, n_features)</span>
<span class="sd">        background_samples</span>
<span class="sd">            background samples used to compute Shapley values,</span>
<span class="sd">            typically randomly sampled from training set</span>

<span class="sd">            :shape: (n_background_samples, n_features)</span>
<span class="sd">        zero_correction: bool</span>
<span class="sd">            set Shapley value to zero if the corresponding feature is zero</span>
<span class="sd">        shapvalue_scale: bool</span>
<span class="sd">            scale Shapley values into [1,Inf) (just for simplicity)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Shapley values</span>
<span class="sd">            :shape: (n_anomaly_samples, n_features)</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Uses `SHAP by Scott Lundberg &lt;https://github.com/slundberg/shap&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_anomaly</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">):</span>
            <span class="n">X_anomaly</span> <span class="o">=</span> <span class="n">X_anomaly</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

        <span class="n">num_background_samples</span> <span class="o">=</span> <span class="n">background_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">num_background_samples</span> <span class="o">&gt;=</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_background_samples</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
            <span class="n">background_samples</span> <span class="o">=</span> <span class="n">background_samples</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">background_samples</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">):</span>
            <span class="n">background_samples</span> <span class="o">=</span> <span class="n">background_samples</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">GradientExplainer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">detector</span><span class="p">,</span> <span class="n">background_samples</span><span class="p">)</span>
        <span class="c1"># explainer = shap.DeepExplainer( self.detector, background_samples )</span>
        <span class="c1"># DeepExplainer is not available</span>

        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_anomaly</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">zero_correction</span><span class="p">:</span>
            <span class="n">shap_values</span><span class="p">[</span><span class="n">X_anomaly</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">shapvalue_scale</span><span class="p">:</span>
            <span class="n">zero_mask</span> <span class="o">=</span> <span class="n">X_anomaly</span> <span class="o">!=</span> <span class="mi">0</span>
            <span class="n">shap_mins</span> <span class="o">=</span> <span class="p">(</span><span class="n">shap_values</span> <span class="o">*</span> <span class="n">zero_mask</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span> <span class="o">-</span> <span class="n">shap_mins</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">shap_values</span><span class="p">[</span><span class="o">~</span><span class="n">zero_mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">shap_values</span></div></div>


<div class="viewcode-block" id="detection_report"><a class="viewcode-back" href="../../psykoda.html#psykoda.detection.detection_report">[docs]</a><span class="k">def</span> <span class="nf">detection_report</span><span class="p">(</span>
    <span class="n">score_sorted</span><span class="p">:</span> <span class="n">Series</span><span class="p">,</span>
    <span class="n">shap_value_idx_sorted</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">shap_top_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataFrame</span><span class="p">:</span>

    <span class="sd">&quot;&quot;&quot;detection report</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    score_sorted</span>
<span class="sd">        anomaly score, sorted in descending order</span>

<span class="sd">        :index:</span>
<span class="sd">            (datetime_rounded, src_ip)</span>
<span class="sd">    shap_value_idx_sorted</span>
<span class="sd">        Shapley values of anomaly samples, sorted in descending order by anomaly score</span>

<span class="sd">        :index:</span>
<span class="sd">            (datetime_rounded, src_ip), top-n of score_sorted</span>
<span class="sd">        :columns:</span>
<span class="sd">            features</span>
<span class="sd">    shap_top_k</span>
<span class="sd">        number of Shapley values to include per (datetime_rounded, src_ip)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    detection_report</span>

<span class="sd">        :index:</span>
<span class="sd">            (datetime_rounded, src_ip)</span>
<span class="sd">        :columns:</span>
<span class="sd">            anomaly_score, shap_top_{i}, top_{i}_shap_value</span>
<span class="sd">            for 0 &lt; i &lt;= shap_top_k</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">score_sorted</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">shap_value_idx_sorted</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

    <span class="n">shap_top_k</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">shap_top_k</span><span class="p">,</span> <span class="n">shap_value_idx_sorted</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[</span><span class="s2">&quot;shap_top_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;top_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_shap_value&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">shap_top_k</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="p">[])</span>
    <span class="n">dtypes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;str&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">shap_top_k</span><span class="p">))</span>
    <span class="n">df_shap</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="n">index</span><span class="o">=</span><span class="n">score_sorted</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtypes</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shap_value_idx_sorted</span><span class="o">.</span><span class="n">index</span><span class="p">):</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_value_idx_sorted</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">sample</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">fe</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;__&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">shap_values</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="n">shap_top_k</span><span class="p">])]</span>
        <span class="n">value</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shap_values</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">shap_top_k</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">shap_top_k</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">value</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">fe</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">df_shap</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">shap_top_k</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="n">fe</span>
        <span class="n">df_shap</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shap_top_k</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="n">df_shap</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;anomaly_score&quot;</span><span class="p">,</span> <span class="n">score_sorted</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df_shap</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">psykoda</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">src</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../app/index.html">Application Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../app_ja/index.html">基本的な使い方</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../app_ja/index.html#id11">ユースケース</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Development Guides</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, KKO.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>